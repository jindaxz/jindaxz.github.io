<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jinda Zhang</title>

    <meta name="author" content="Jinda Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jinda Zhang
                  <p>Hi thereðŸ‘‹, Iâ€™m currently pursuing graduate studies at Northeastern University, actively engaging in various cutting-edge research projects and industrial applications in machine learning, artificial intelligence, and natural language processing.</p>

                  <p>As a Research Intern at SLangLab under the guidance of <a href="https://aanchan.github.io/projects/">Prof. Aanchan Mohan</a> , I focus on advancing Unified-Modal Speech-Text Pre-Training Models, developing speech recognition systems for atypical patterns, and enhancing accessibility through AI-powered technologies.</p>
                  
                  <p>In addition, Iâ€™m a Research Intern at <a href="https://www.lapis.rocks/">Lapis Lab</a> (University of Illinois Urbana-Champaign). I also have been involved in integrating large language models (LLMs) into Human-Computer Interaction systems, working on AI avatars and social VR environments to assist users with social and cognitive challenges in Khoury HCI advised by <a href="https://www.khoury.northeastern.edu/people/mirjana-prpa/">Prof. Mirjana Prpa</a> .</p>
                  
                  <p>Furthermore, I have contributed to computer vision research, developing AI solutions for sustainable forest management through remotely piloted aircraft systems (RPAS) during <a href="https://www.khoury.northeastern.edu/information-for-overview/current-masters-and-certificate-students/khoury-research-apprenticeship/">Khoury Research Apprenticeship</a>./p>
                  
                  <p>On the leadership side, Iâ€™ve mentored research teams in speech and language technologies and led weekly check-in meetings to guide collaborative efforts, enhancing the social impact of our work in real-world applications.</p>
                  
                <p style="text-align:center">
                  <a href="zhang.jinda1@northeastern.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/resume-data-sci-jinda-zhang.docx.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=h4UcbXUAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="#">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jindaznb/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/jinda-zhang.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/jinda-zhang.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I work on speech and language processing, multimodal large language models, generative models. 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          
            <tr onmouseout="slp_stop()" onmouseover="slp_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='slp_img'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/amg_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/speech.png' width="160">
                </div>
                <script type="text/javascript">
                  function slp_start() {
                    document.getElementById('slp_img').style.opacity = "1";
                  }
                  function slp_stop() {
                    document.getElementById('slp_img').style.opacity = "0";
                  }
                  slp_stop()
                </script>
              </td>
              <td style="padding:10px;width:75%;vertical-align:middle">
                <a href="#">
                  <span class="papertitle">Inclusive Speech Recognition</span>
                </a>
                <br>
                
                <strong>Jinda Zhang</strong>, 
                <a href="#">Aanchan Mohan</a>




                <br>
                <em>Arxiv</em>, 2024
                <br>
                <a href="#">Ongoing</a>
                <!-- <a href="https://www.youtube.com/watch?v=BF_LJsic8Zw">Demo</a> -->
                <!-- <a href="https://github.com/zshyang/amg">data</a> -->
                <p></p>
                <p>We introduce speech and language processing and multimodal LLMs for Atypical speech.
                </p>
              </td>
            </tr> 
         


            <tr onmouseout="agent_stop()" onmouseover="agent_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='agent_img'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/amg_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/chi-lbw.png' width="160">
                </div>
                <script type="text/javascript">
                  function agent_start() {
                    document.getElementById('agent_img').style.opacity = "1";
                  }
                  function agent_stop() {
                    document.getElementById('agent_img').style.opacity = "0";
                  }
                  agent_stop()
                </script>
              </td>
              <td style="padding:10px;width:75%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/10.1145/3613905.3651026">
                  <span class="papertitle">Building LLM-based AI Agents in Social Virtual Reality</span>
                </a>
                <br>
                
                <a href="#">Hongyu Wan</a>,
                <strong>Jinda Zhang</strong>, 
                <a href="#">Abdulaziz Arif Suria</a>,
                <a href="#">Bingsheng Yao</a>,
                <a href="#">Dakuo Wang</a>,
                <a href="#">Yvonne Coady</a>,
                <a href="#">Mirjana Prpa</a>



                <br>
                <em>CHI LBW</em>, 2024
                <br>
                <a href="https://dl.acm.org/doi/10.1145/3613905.3651026">Paper</a> /
                <a href="https://www.youtube.com/watch?v=BF_LJsic8Zw">Demo</a>
                <!-- <a href="https://github.com/zshyang/amg">data</a> -->
                <p></p>
                <p>We introduce the design and evaluation of an LLMbased AI agent for human-agent interaction in Virtual Reality (VR).
                </p>
              </td>
            </tr> 
         


            <tr onmouseout="agent_stop()" onmouseover="agent_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='agent_img'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/amg_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/fire.png' width="160">
                </div>
                <script type="text/javascript">
                  function agent_start() {
                    document.getElementById('agent_img').style.opacity = "1";
                  }
                  function agent_stop() {
                    document.getElementById('agent_img').style.opacity = "0";
                  }
                  agent_stop()
                </script>
              </td>
              <td style="padding:10px;width:75%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/10.1145/3613905.3651026">
                  <span class="papertitle">Enhancing Tree Type Detection in Forest Fire Risk Assessment: Multi-Stage Approach and Color Encoding with Forest Fire Risk Evaluation Framework for UAV Imagery
                  </span>
                </a>
                <br>
                
                <strong>Jinda Zhang</strong> 
                <br>
                <em>Arxiv</em>, 2024
                <br>
                <a href="https://arxiv.org/pdf/2407.19184">Paper</a>
                <!-- <a href="https://www.youtube.com/watch?v=BF_LJsic8Zw">Demo</a> -->
                <!-- <a href="https://github.com/zshyang/amg">data</a> -->
                <p></p>
                <p> Our findings demonstrate the effectiveness of multi-stage detectors and optimizations in improving the accuracy of forest fire risk assessment.
                </p>
              </td>
            </tr>

            </tr> 

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                <h2>Misc</h2>
                <p>
                  When I am not coding or reading papers, I enjoy <a href="https://www.maa.org/math-competitions/putnam-competition">math competition puzzles</a>, reading, and playing chess.

                </p>
              </td>
            </tr>
          </tbody></table>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website's template is taken from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
